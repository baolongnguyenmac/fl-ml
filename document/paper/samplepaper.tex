% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.20 of 2017/10/04
%
\documentclass[runningheads]{llncs}
%
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
% \usepackage{pdfpages}
% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following line
% to display URLs in blue roman font according to Springer's eBook style:
% \renewcommand\UrlFont{\color{blue}\rmfamily}

% % Dãn dòng 1.5
% \usepackage{setspace}
% \onehalfspacing

% Font tiếng Việt
\usepackage[T5]{fontenc}
\usepackage[utf8]{inputenc}
\DeclareTextSymbolDefault{\DH}{T1}

% Chèn và định dạng mã giả
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\makeatletter
\def\BState{\State\hskip-\ALG@thistlm}
\makeatother

% chèn inline code
\usepackage{xparse}
\NewDocumentCommand{\codeword}{v}{%
    \texttt{\textcolor{blue}{#1}}%
}

% equation
\usepackage{breqn}
\usepackage{amsfonts}
\usepackage{bm}

% Bảng biểu
\usepackage{multirow}
\usepackage{float}
\usepackage{makecell}
\usepackage{rotating}
\usepackage{vcell}
\usepackage{array}
\usepackage{diagbox}
\usepackage{booktabs}
\usepackage{colortbl}
\newcolumntype{L}[1]{>{\raggedright\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{C}[1]{>{\centering\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{R}[1]{>{\raggedleft\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}

\begin{document}
%
\title{Meta-learning and Personalization layer \\in Federated learning}
%
% \titlerunning{Abbreviated paper title}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%
\author{Nguyen Bao Long\inst{1}\orcidID{0000-0002-6411-8943} \and
Cao Tat Cuong\inst{1}\orcidID{0000-0003-1803-843X} \and Le Hoai Bac\inst{1}\orcidID{unknown}}
%
\authorrunning{Long-Cuong et al.}
% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
\institute{VNU HCM University of Science, Ho Chi Minh City 749000, Vietnam}
%
\maketitle              % typeset the header of the contribution
%
\begin{abstract}
The concept of \textit{Federated Learning} (FL) and the algorithm \textit{Federated Averaging} were born, which is seen as an alternative to centralized training. This solution not only achieves almost the same efficiency as existing deep learning methods, solves the hardware cost problem, but also ensures the privacy of user data. However, in the face of highly individualized and heterogeneous data per user (not independent and identically distributed or non-IID data), the system suffered severe performance degradation \cite{zhao2018federated}. This study improves the performance and personalization of the FL system on non-IID data by the algorithm \codeword{FedMeta-Per} - a combination of the meta-learning training method \cite{hospedales2020meta} and the personalization layer technique \cite{zhu2021federated} into the FL system.

\keywords{Federated learning \and non-IID \and Meta-learning \and Personalization layer.}
\end{abstract}
%
%
%

\section{Introduction}

In the era of Internet of Things (IoT), facing a huge amount of data at the edge devices generated every second, the centralized training process presents many disadvantages. First, the data at the edge devices often contains sensitive information about the user. When it has to be transmitted to a server for training, this information can be exposed, seriously affecting data privacy. Second, the cost of transmitting information between the server and the clients is very expensive because a large amount of data must be transferred to the server. Third, the server must have large computing power and storage to conduct the training process.

Edge computing \cite{khan2019edge} was born to push the computation and storage of data from the server to clients or edge devices, reducing the load on the server. Furthermore, the computation is moved to or near the data generation site, which saves huge amounts of communication costs and reduces computational latency. Not only that, the process of exchanging data between the server and the clients no longer takes place, greatly increasing the user's data privacy.

In the spirit of edge computing, \textit{federated learning} (FL) \cite{mcmahan2017communication} was born, to train a machine learning model on separate data sets, distributed on edge devices \cite {yin2021comprehensive}. Specifically, the goal of the FL system is to find a global parameter $w_G^*$ such that the system error is minimized:

\begin{dmath}
    w_G^* = \arg\min_{w_G}{f_{global}(w_G)}
        = \arg\min_{w_G}{\frac{1}{n} \sum_{i=1}^n{f_{local}(w_i)}}
\end{dmath} where, $n$ is the number of clients participating in the system, $f_{global}$ is the error of the whole system, $f_{local}(w_i)$ is the error of the client $i$ when it use the parameter $w_i$.

This training method not only inherits the benefits of edge computing (lowering hardware costs and latency, increased data security) but also has the potential to increase personalization for each user. However, the clients participating in the system are often heterogeneous in terms of storage and computing capacity. The data distributed across these clients is also not uniformly distributed (non-IID). This creates two main challenges of an FL system: the Systemic Challenge and the Statistical Challenge \cite{li2020federated}. As for the statistical challenge, \cite{zhao2018federated} research indicates that FL's traditional algorithm - Federated Averaging (\codeword{FedAvg}) suffers from severe performance loss on non-IID data. This study aims to partially solve the statistical problem. Specifically, the study focuses on improving performance as well as personalization in prediction on non-IID data.

In this study, we improve the performance of the FL system on non-IID data by meta-learning (ML) \cite{hospedales2020meta} and personalization layer (PL) technique. Bilevel optimization-based ML algorithms can generate a quick adaptive initialization on the new task. The use of ML algorithms in training aims to obtain a global parameter that can adapt quickly on the new data set of each user. Meanwhile, the use of PL techniques to maintain part of the deep neural network at the edge devices further improves personalization.

\textbf{Contribution}. The study proposes the \codeword{FedMeta-Per} algorithm, a combination of ML algorithms (\codeword{MAML} \cite{finn2017model}, \codeword{Meta-SGD} \cite{li2017meta}) and PL techniques (\codeword{FedPer} \cite{arivazhagan2019federated}, \codeword{LG-FedAvg} \cite{liang2020think}), which helps to increase accuracy and personalize for each user. Experimentally, the research shows the effectiveness in increasing the accuracy as well as the personalization of the proposed algorithm compared with the algorithm \codeword{FedAvg}; algorithms that incorporate ML into FL \cite{chen2018federated} (\codeword{FedMeta(MAML)}, \codeword{FedMeta(Meta-SGD)}) and algorithms that use PL (\codeword{FedPer}) on a FL system of 50 users, containing the data of two datasets MNIST \cite{deng2012mnist} and CIFAR-10 \cite{krizhevsky2009learning} respectively.

\section{Related Work}

Since the \codeword{FedAvg} algorithm was first introduced in 2017, a lot of work has been done to improve the accuracy of the system on non-IID data. Here, the study reviews a few typical works in the realization of this goal.

% \textbf{Sử dụng dữ liệu}. Nếu thiếu trang sẽ viết thêm

% \textbf{Sử dụng nhiều máy chủ}. Nếu thiếu trang sẽ viết thêm

\textbf{Meta-learning based approach}. ML is a new learning method that allows the learning model to increase experience by performing many different tasks in the same task distribution. This results in ML models being able to adapt quickly on new tasks after only a few training steps with limited training data. This is an important discovery, playing a role in bringing machine learning closer to human learning \cite{harlow1949formation}.

% Cụ thể, trong cài đặt của ML cho bài toán học có giám sát, tập dữ liệu huấn luyện và kiểm tra lần lượt là $\mathcal{D}_{train} = \{ ( \mathcal{D}_{train(i)}^{support}, \mathcal{D}_{train(i)}^{query} ) \}_{i=1}^{|\mathcal{D}_{train}|}$ và $\mathcal{D}_{test} = \{ ( \mathcal{D}_{test(i)}^{support}, \mathcal{D}_{test(i)}^{query} ) \}_{i=1}^{|\mathcal{D}_{test}|}$. Mỗi phần tử trong các tập dữ liệu trên bao gồm tập support và query và đại diện cho một nhiệm vụ. Theo đó, 

In the context of non-IID data, each user, with different needs, generates datasets with very different distributions. If we consider each user as a task, training the global model on a set of users (FL system) is equivalent to training the machine learning model on an task distribution (ML approach). Research \cite{chen2018federated} proposes framework \codeword{FedMeta} and experimentally illustrates by two algorithms \codeword{FedMeta(MAML)}, \codeword{FedMeta(Meta-SGD)}. The results show that the global model has a fast adaptability, faster convergence than \codeword{FedAvg} on the LEAF dataset \cite{caldas2018leaf}. The study \cite{fallah2020personalized} proposes the combination of \codeword{MAML} on the CIFAR-10 dataset and the study \cite{jiang2019improving} proposes the combination \codeword{Reptile} \cite{nichol2018first} on the EMNIST-62 dataset \cite{cohen2017emnist} to the FL system to increase personalization on each client.

An FL system, on the other hand, will have new clients over time. One downside for systems that use ML in training is that they treat clients that have been around for a long time in the system and those that have just joined the system. Therefore, although global models are able to adapt quickly to new data, their performance can be further improved.

\textbf{Personalization layer approach}. To capture the data properties, which are highly personalized on different users, dividing the deep neural network into personalization layers and base layers, and maintaining the personalization layers at each client (base layers will be co-trained by the clients) is suggested. Accordingly, the study \cite{arivazhagan2019federated} proposes the \codeword{FedPer} algorithm with the idea of maintaining fully-connected layers of the deep neural network at the clients with the goal of increasing personalization. Experimentally, \codeword{FedPer} achieved much higher results than \codeword{FedAvg} when tested on the data sets CIFAR-10 and CIFAR-100. In addition, the study \cite{liang2020think} with the algorithm \codeword{LG-FedAvg} proposes to maintain the feature extraction layers of the deep neural network at the clients with the goal of capturing the features of each different clients. The results obtained are even better than \codeword{FedPer} in most cases when testing on a system consisting of 10 to 100 users containing data of the data sets CIFAR-10, CIFAR- 100 and Omniglot \cite{lake2015human}.

The similarity between these two methods lies in the training base layers. These layers are trained and synthesized using the \codeword{FedAvg} algorithm. Therefore, they are not able to adapt quickly on the new data set. In addition, during inference phase, the \codeword{FedPer} algorithm takes the average of the parameters of the personalization layers, then combines with the parameters of the base layers to conduct the test. The parameter of personalization layers, which is highly personalized, is now averaged, which can cause the classification efficiency to be significantly reduced when the data is strong non-IID. The algorithm \codeword{LG-FedAvg} proposes to perform an ensemble test between personalization layers. However, only personalization layers trained on the same data as the test data will really perform well. Therefore, in some cases, ensemble test results are not high because there are too many personalization layers that have never worked with the same data as the data during the test.

\section{Proposed Method}

The proposed method of this study is a combination of maintaining personalization layers at the edge device of the algorithm \codeword{FedPer} and using meta-learning in training base layers of the model. With this combination, the research aims at two goals: (1) - Fast adaptability on new dataset of ML algorithms, (2) - High personalization ability of PL techniques.

% nói về việc các lớp phần chung thì gà, ml khắc phục vụ này
\textbf{Fast adaption}. As mentioned above, the base layers of algorithms using PL techniques are not really strong because they are trained on the \codeword{FedAvg} algorithm, which leads to them being slow to adapt to the data set. new. The training of base layers by ML algorithms is expected to provide these base layers with the ability to quickly adapt on the data set of clients, overcoming the disadvantages of algorithms using PL techniques.

% nói về tính cá nhân hoá
\textbf{High personalization}. The personalization of the FL system combined with ML comes from the fact that the system allows the global model to perform a fine-tune on part of the client data before going into testing on the rest of the client data. there. Allowing to maintain a portion of the deep neural network (personalization layers) on each client also greatly increases the ability to personalize each user. Here, \codeword{FedMeta-Per} proposes a combination of the two methods of personalization enhancement mentioned above, which is expected to further increase the personalization of the FL system.

Specifically, the deep neural network is divided into two parts, the base layers include feature extraction layers, and the personalization layers contain fully-connected layers. The base layers are trained against two ML algorithms (\codeword{MAML} and \codeword{Meta-SGD}). The personalization layers are maintained at separate clients. With this combination, we call our proposed algorithm \codeword{FedMeta-Per}.

\begin{algorithm}[h]
    \caption{FedMeta-Per (Server)} \label{alg:fedmeta_per_server}
    \begin{algorithmic}[1]
        \State Initialize $w_B^0$ for MAML or ($w_B^0, \alpha_B^0$) for Meta-SGD
        \For{$t=0,1,2,...$}
            \State Sample a subset $C_t$ of $m$ clients
            \For{$c_i \in C_t$}
                \State $w_{B(i)}^{t+1} \gets$ ModelTrainingMAML($c_i, w_B^t$) for MAML
                \State $(w_{B(i)}^{t+1}, \alpha_{B(i)}^{t+1}) \gets$ ModelTrainingMetaSGD($c_i, w_B^t, \alpha_B^t$) for Meta-SGD
            \EndFor

            \State
            \State {$n_i = \left| \mathcal{D}_{train(i)}^{query} \right|, N_m = \sum_{i=0}^m n_i$}
            \State Aggregate $w_{B}^{t+1} = \sum_{i=0}^m \frac{n_i}{N_m} w_{B(i)}^{t+1}$ for MAML
            \State Aggregate $(w_B^{t+1}, \alpha_B^{t+1}) = \sum_{i=0}^m \frac{n_i}{N_m} (w_i^{t+1}, \alpha_{B(i)}^{t+1})$ for Meta-SGD
        \EndFor
    \end{algorithmic}
\end{algorithm}

\textbf{Training phase}. At the server, the algorithm \ref{alg:fedmeta_per_server} is implemented to coordinate the training activities. These operations include: Parameter initialization of base layers; Distribute this parameter to clients; Synthesize the parameters of the new global base layers. This process is summarized in Table \ref{tab:param_fedmetaper}. For the \codeword{MAML} algorithm, the base layers parameters include only part of the global model parameters ($w_B^t$ at round $t$). Meanwhile, the parameter of the \codeword{Meta-SGD} algorithm's base layers contains an extra part of the learning rate at each client ($\alpha_B$ at round $t$), which is the same size as $w_B^t$. This learning rate value will be well explained in the training at the clients. These values will be distributed to a subset $C_t$ of $m$ clients to conduct distributed training. The clients then perform training on their own dataset and return the parameters of the base layers ($w_{B(i)}^{t+1}$ for \codeword{MAML} and $( w_{B(i)}^{t+1}, \alpha_{B(i)}^{t+1})$ for \codeword{Meta-SGD} at round $t$) for the server. The parameters of the new base layers are summarized as follows:

\begin{dmath}
    \text{MAML: } w_{B}^{t+1} = \sum_{i=0}^m \frac{n_i}{N_m} w_{B(i)}^{t+1}
\end{dmath}

\begin{dmath}
    \text{Meta-SGD: } (w_B^{t+1}, \alpha_B^{t+1}) = \sum_{i=0}^m \frac{n_i}{N_m} (w_i^{t+1}, \alpha_{B(i)}^{t+1})
\end{dmath} where, $n_i$ is the number of data samples of the client's query set $c_i\in C_t$, $N_m$ is the total number of data samples on the query set of $m$ of the client participating in global training.

\begin{table}[h]
    \centering
    \caption{Server activity summary at round $t^{th}$}
    \label{tab:param_fedmetaper}
    % \resizebox{\linewidth}{!}{%
    \begin{tabular}{l|c|c} 
    \toprule
    \multirow{2}{*}{} & \multicolumn{2}{c}{Algorithm}                                               \\ 
    \cline{2-3}
                      & MAML                          & Meta-SGD                                     \\ 
    \hline
    Send              & $w_B^t$                                & $(w_B^t, \alpha_B^t)$                        \\
    Receive           & Weights: $w_{B(i)}^{t+1}, i\in [1,m]$  & Parameters: $(w_{B(i)}^{t+1}, \alpha_{B(i)}^{t+1}), i\in [1,m]$  \\
    Aggregate         & $w_{B}^{t+1}$                          & $(w_B^{t+1}, \alpha_B^{t+1})$                    \\
    \bottomrule
    \end{tabular}
    % }
\end{table}

\begin{algorithm}[h]
    \caption{FedMeta-Per (MAML Client)} \label{alg:fedmaml_per_client}
    \begin{algorithmic}[1]
        \State\textbf{ModelTrainingMAML($c_i, w_B^t$):}
        \State Sample support set $\mathcal{D}_{train(i)}^{support}$ and query set $\mathcal{D}_{train(i)}^{query}$
        \If {$t=0$}
            \State Initialize $w_{P(i)}^t$
        \Else
            \State Load $w_{P(i)}^t$ from the external memory
        \EndIf
        \State $w_i^t \gets w_B^t \bigoplus w_{P(i)}^t$ \Comment{Merge $w_B^t$ and $w_{P(i)}^t$ to form $w_i^t$}
        \State Training: 
        \begin{dmath*}
            \hat{w}_{i}^{t+1} \gets w_{i}^t - \alpha\nabla_{w_i^t} f_{local}\left(w_{i}^t, \mathcal{D}_{train(i)}^{support}\right)
        \end{dmath*}
        \begin{dmath*}
            w_{i}^{t+1} \gets w_{i}^t - \beta\nabla_{w_i^t} f_{local}\left(\hat{w}_{i}^{t+1}, \mathcal{D}_{train(i)}^{query}\right)
        \end{dmath*}
        \State $w_{B(i)}^{t+1}, w_{P(i)}^{t+1} \gets w_i^{t+1}$ \Comment{Resolve $w_i^{t+1}$ to form $w_{B(i)}^{t+1}$ and $w_{P(i)}^{t+1}$}
        \State Send $w_{B(i)}^{t+1}$ to server and store $w_{P(i)}^{t+1}$
    \end{algorithmic}
\end{algorithm}

\begin{algorithm}[h]
    \caption{FedMeta-Per (Meta-SGD Client)} \label{alg:fedsgd_per_client}
    \begin{algorithmic}[1]
        \State\textbf{ModelTrainingMetaSGD($c_i, w_B^t, \alpha_B^t$):}
        \State Sample support set $\mathcal{D}_{train(i)}^{support}$ and query set $\mathcal{D}_{train(i)}^{query}$
        \If {$t=0$}
            \State Initialize $(w_{P(i)}^t, \alpha_{P(i)}^t)$
        \Else
            \State Load $(w_{P(i)}^t, \alpha_{P(i)}^t)$ from the external memory
        \EndIf
        \State $w_i^t \gets w_B^t \bigoplus w_{P(i)}^t$ \Comment{Merge $w_B^t$ and $w_{P(i)}^t$ to form $w_i^t$}
        \State $\alpha_i^t \gets \alpha_B^t \bigoplus \alpha_{P(i)}^t$ \Comment{Merge $\alpha_B^t$ and $\alpha_{P(i)}^t$ to form $\alpha_i^t$}
        \State Training:
        \begin{dmath*}
            \hat{w}_{i}^{t+1} \gets w_{i}^t - \alpha_i^t\circ\nabla_{w_i^t} f_{local}\left(w_{i}^t, \mathcal{D}_{train(i)}^{support}\right)
        \end{dmath*}
        \begin{dmath*}
            (w_{i}^{t+1}, \alpha_i^{t+1}) \gets (w_{i}^t, \alpha_{i}^{t}) - \beta\nabla_{(w_i^t, \alpha_i^t)} f_{local}\left(\hat{w}_{i}^{t+1}, \mathcal{D}_{train(i)}^{query}\right)
        \end{dmath*}
        \State $w_{B(i)}^{t+1}, w_{P(i)}^{t+1} \gets w_i^{t+1}$ \Comment{Resolve $w_i^{t+1}$ to form $w_{B(i)}^{t+1}$ và $w_{P(i)}^{t+1}$}
        \State $\alpha_{B(i)}^{t+1}, \alpha_{P(i)}^{t+1} \gets \alpha_i^{t+1}$ \Comment{Resolve $\alpha_i^{t+1}$ to form $\alpha_{B(i)}^{t+1}$ và $\alpha_{P(i)}^{t+1}$}
        \State Send $(w_{B(i)}^{t+1}, \alpha_B^{t+1})$ to server and store $(w_{P(i)}^{t+1}, \alpha_{P(i)}^{t+1})$
    \end{algorithmic}
\end{algorithm}

At the clients, one of two algorithms \ref{alg:fedmaml_per_client} and \ref{alg:fedsgd_per_client} are implemented, corresponding to the training method of the type \codeword{MAML} and \codeword{Meta-SGD} . To train the model on bilevel optimization-based ML algorithms , the client data is divided into support set ($\mathcal{D}_{train(i)}^{support}$) and query set ( $\mathcal{D}_{train(i)}^{query}$). The training steps at the client include: Merge parameters of base layers and personalization layers to form complete model parameters; Perform training according to ML algorithms; New model parameter resolution.

Specifically, for clients that train on the \codeword{MAML} algorithm, at the $t$ global training step, client $c_i$ will receive an initialization weight $w_B^t$ of the base layers sent by the server. Next, $c_i$ merges the weight of the base layers $w_B^t$ with the weight of the personalization layers $w_{P(i)}^t$ to get the weight of the complete model $w_i^t$ . $w_i^t$ is then trained as follows:

\begin{dmath}
    \text{Train: } \hat{w}_{i}^{t+1} \gets w_{i}^t - \alpha\nabla_{w_i^t} f_{local}\left(w_{i}^t, \mathcal{D}_{train(i)}^{support}\right)
\end{dmath}

\begin{dmath}
    \text{Meta-train: } w_{i}^{t+1} \gets w_{i}^t - \beta\nabla_{w_i^t} f_{local}\left(\hat{w}_{i}^{t+1}, \mathcal{D}_{train(i)}^{query}\right)
\end{dmath} where, $\alpha, \beta\in [0,1]$ are the learning rates.

For clients that use the \codeword{Meta-SGD} algorithm in training, the base layers of the deep neural network include two parameters: the weight of the base layers $w_B^{t}$ and the learning rate of the base layers $\alpha_B^{t}$; personalization layers of the network include two parameters $w_{P(i)}^{t}$ and $\alpha_{P(i)}^{t}$ (same size as $w_{P(i) )}^{t}$). Parameter merging also takes place between the parameters of base layers and personalization layers to form the complete parameter set $w_i^t$ and $\alpha_i^t$. It should be noted that \codeword{Meta-SGD} configures $\alpha$ as a learning rate array of the size of the model weight and treats $\alpha$ as a trainable parameter. Thus, the algorithm perform element-wise multiplication between $\alpha$ and the derivative of the error function in the Equation \ref{eq:opt_metasgd_1} and performs the derivative with respect to $\alpha$ in the Equation \ref{eq:opt_metasgd_2}.

\begin{dmath}
    \label{eq:opt_metasgd_1}
    \text{Train: } \hat{w}_{i}^{t+1} \gets w_{i}^t - \alpha_i^t\circ\nabla_{w_i^t} f_{local}\left(w_{i}^t, \mathcal{D}_{train(i)}^{support}\right)
\end{dmath}

\begin{dmath}
    \label{eq:opt_metasgd_2}
    \text{Meta-train: } (w_{i}^{t+1}, \alpha_i^{t+1}) \gets (w_{i}^t, \alpha_{i}^{t}) - \beta\nabla_{(w_i^t, \alpha_i^t)} f_{local}\left(\hat{w}_{i}^{t+1}, \mathcal{D}_{train(i)}^{query}\right)
\end{dmath}

\textbf{Inference phase}. Based on the testing process of the \cite{liang2020think} study, we divide into two types of users: local clients and new clients. For local clients, private deep classes are reused to achieve a high degree of personalization. For new clients, we do not use ensemble testing techniques as suggested by the \cite{liang2020think} study, but for each of the previously built personalization layers combined with base layers to operate on the new dataset. During the fine-tune process, the client selects the parameter set for the smallest error. Then use this set of parameters to process test data.

\section{Numerical Experiments}

\textbf{Dataset}. The study evaluates the proposed algorithm on 50 clients containing two datasets MNIST \cite{deng2012mnist} and CIFAR-10 \cite{krizhevsky2009learning}, respectively. To simulate non-IID data, each client is configured to contain only 2/10 data subclasses, the amount of data between clients is uneven. At each client, the data is divided between the support and query sets at a ratio of 2:8. Data statistics are presented in Table \ref{tab:stat_noniid_data}.

\begin{table}[h]
    \caption{Statistics on MNIST and CIFAR-10 (non-IID data)}
    \label{tab:stat_noniid_data}
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{ccccccccc}
    \toprule
    \multirow{2}{*}{Dataset} & \multirow{2}{*}{\#clients} & \multirow{2}{*}{\#samples} & \multirow{2}{*}{\#classes} & \multicolumn{4}{c}{\#samples/client} & \multirow{2}{*}{\#classes/client} \\ \cline{5-8}
                             &                            &                            &                            & min    & mean    & std     & max     &                                   \\ \hline
    MNIST                    & 50                         & 69,909                     & 10                         & 135    & 1,398   & 1,424   & 5,201   & 2                                 \\
    CIFAR-10                 & 50                         & 52,497                     & 10                         & 506    & 1,049   & 250     & 1,986   & 2                                 \\
    \bottomrule
    \end{tabular}%
    }
\end{table}

\textbf{Metrics}. The study evaluates the model through the following metrics: Accuracy in correlation with all data points ($acc_{micro}$), Accuracy in correlation with all clients ($acc_{macro}$) and F1-score ($F1_{macro}$).

\textbf{Experiments}. This study performs centralized and distributed experiments on the same model architecture. For distributed training, the study experimented on algorithms \codeword{FedAvg}, \codeword{FedPer}, \codeword{FedMeta(MAML)}, \codeword{FedMeta(Meta-SGD)}. The results are compared with the proposed algorithm \codeword{FedMeta-Per}. For a fair comparison, the study allows the global model obtained by the \codeword{FedAvg} and \codeword{FedPer} algorithms to perform a fine-tune one or several times on the client's support set during the inference phase. This is the idea of \codeword{FedAvgMeta} and \codeword{FedPerMeta} algorithms.

Details of the experimental settings can be found in Appendix \ref{appendix}.

\section{Results \& Discussion}

\textbf{Centralized \& Decentralized}. The results of centralized training and distributed training (\codeword{FedAvg} on IID and non-IID data) are presented in Table \ref{fig:central_decentral}. It is easy to see that the centralized training model achieves higher results on all metrics. Results obtained on \codeword{FedAvg} (IID data) are 7\% to 8\% lower because the global model captures the features indirectly (through parametric averaging at the server). However, when the input data is non-IID, the metrics decrease from 9\% to 13\% on MNIST and do not reach convergence on CIFAR-10. Metrics on non-IID data also differ quite a lot (3\% - 6\% on MNIST and 3\% - 4\% on CIFAR-10) compared to differences on IID data (below 1\%). This proves that the uneven data distribution across the clients has adversely affected the classification quality.

\begin{table}[h]
    \centering
    \caption{Classification results (\%) of centralized and decentralized (FedAvg on IID and non-IID data) using MNIST and CIFAR-10 datasets. Best results per metrics are boldfaced.}
    \label{fig:central_decentral}
    % \resizebox{\linewidth}{!}{%
    \begin{tabular}{c|l|ccc} 
    \toprule
    \multicolumn{1}{c}{}      &                       & $acc_{micro}$  & $acc_{macro}$ & $F1_{macro}$    \\ 
    \hline
    \multirow{4}{*}{MNIST}    & Centralized           & \textbf{97.07} & -             & \textbf{97.04}  \\
                              & FedAvg (IID data)     & 90.36          & 90.34±2.24    & 90.12±2.29      \\
                              & FedAvg (local client) & 85.03          & 82.14±14.76   & 79.43±16.83     \\
                              & FedAvg (new client)   & 83.92          & 81.69±19.71   & 77.66±22.54     \\ 
    \hline
    \multirow{4}{*}{CIFAR-10} & Centralized           & \textbf{61.91} & -             & \textbf{61.72}  \\
                              & FedAvg (IID data)     & 53.83          & 53.83±3.14    & 53±3.21         \\
                              & FedAvg (local client) & 19.02          & 19.29±25.11   & 16.85±23.92     \\
                              & FedAvg (new client)   & 24.63          & 24.83±22.57   & 20.52±20.45     \\
    \bottomrule
    \end{tabular}
    % }
\end{table}

\textbf{Convergence ability}. The results on metrics of the \codeword{FedMeta-Per} algorithm and the algorithms used in the comparison are presented in Table \ref{tab:compare}. To solve the problem of non-IID data, the technique of fine-tune localizes the FL system in a simple form (algorithm \codeword{FedAvgMeta}), in order to improve the adaptability and personalization of the model on the new data set. However, the results obtained in Table \ref{tab:compare} as well as in Figure \ref{fig:fedpermeta_vs_chicken} are not very satisfactory (low convergence on the MNIST dataset and not on the CIFAR-10 dataset). The reason for \codeword{FedAvgMeta} not to converge is that the adaptability of the global model to the new dataset is very low. The PL technique is also used in the form of two algorithms \codeword{FedPer} and \codeword{FedPerMeta}. However, the results obtained are even worse than \codeword{FedAvg} and \codeword{FedAvgMeta}. This is understandable given that the modeling architecture used by the \cite{arivazhagan2019federated} study is a pre-trained network \codeword{MobileNet-v1} \cite{howard2017mobilenets} - a more complex deep neural network of this study a lot (see Appendix \ref{model_architecture}). This also proves that using PL technique is not enough in handling non-IID data.

% \rotatebox[origin=c]{90}{\begin{tabular}[c]{@{}c@{}}local client\end{tabular}}
\begin{table}[h]
    \centering
    \caption{Classification results (\%) of FedAvg, FedPer and FedMeta-Per using MNIST and CIFAR-10 datasets. Best results per metrics are boldfaced.}
    \label{tab:compare}
    \resizebox{\linewidth}{!}{%
    \begin{tabular}{c|l|ccc|ccc} 
    \toprule
    \multicolumn{1}{l}{} &                                         & \multicolumn{3}{c|}{CIFAR-10}                                & \multicolumn{3}{c}{MNIST}                                                                                 \\ 
    \cline{3-8}
    \multicolumn{1}{l}{} & \multicolumn{1}{c|}{}                   & $acc_{micro}$    & $acc_{macro}$          & $F1_{macro}$           & \multicolumn{1}{l}{$acc_{micro}$} & \multicolumn{1}{l}{$acc_{macro}$} & \multicolumn{1}{l}{$F1_{macro}$}  \\ 
    \hline
    \multirow{8}{*}{\rotatebox[origin=c]{90}{\begin{tabular}[c]{@{}c@{}}local client\end{tabular}}} & FedAvg                                  & 19.02          & 19.29±25.11          & 16.85±23.92          & 85.03                             & 82.14±14.76                       & 79.43±16.83             \\
                         & FedPer                                                                                                             & 13.22          & 12.99±19.39          & 10.52±14.91          & 77.29                             & 75.48±14.84                       & 72.32±15.99                        \\
                         & FedAvgMeta                                                                                                         & 40.3           & 38.47±31.52          & 33.81±30.61          & 84.84                             & 81.56±16.68                       & 78.31±19.8                        \\
                         & FedPerMeta                                                                                                         & 18.57          & 17.48±22.55          & 14.54±18.67          & 75.91                             & 74.11±16.2                        & 71.22±16.77                        \\
                         & FedMeta(MAML)                                                                                                      & 69.02          & 68.76±14.86          & 61.14±20             & 92.99                             & 91.14±5.99                        & 90.16±6.28                        \\
                         & FedMeta(Meta-SGD)                                                                                                  & 78.63          & 78.73±11.59          & 72.87±18.31          & 98.02                             & 96.35±4.62                        & 95.80±5.51                        \\
                         & \textbf{FedMeta-Per(MAML)}                                                                                         & \textbf{86.6}  & \textbf{86.52±6.31}  & \textbf{85.33±6.77}  & \textbf{99.37}                    & \textbf{99.12±1.29}               & \textbf{98.94±1.6}                \\
                         & \textbf{FedMeta-Per(Meta-SGD)}                                                                                     & 85.61          & 85.68±7.22           & 85.08±7.32           & 98.92                             & 98.15±3.32                        & 98.20±2.94                        \\ 
    \hline
    \multirow{8}{*}{\rotatebox[origin=c]{90}{\begin{tabular}[c]{@{}c@{}}new client\end{tabular}}} & FedAvg                                    & 24.63          & 24.83±22.57          & 20.52±20.45          & 83.92                             & 81.69±19.71                       & 77.66±22.54             \\
                         & FedPer                                                                                                             & 14.4           & 14.52±20.15          & 10.66±13.79          & 78.3                              & 76.19±18.79                       & 72.72±19.3                         \\
                         & FedAvgMeta                                                                                                         & 43.39          & 43.54±18             & 35.14±17.22          & 84.34                             & 82.37±17.42                       & 78.78±19.31                         \\
                         & FedPerMeta                                                                                                         & 13.33          & 13.57±19.62          & 10.05±13.17          & 77.47                             & 75.56±20.33                       & 72.60±21.37                         \\
                         & FedMeta(MAML)                                                                                                      & 61.69          & 61.64±12.49          & 50.76±19.2           & 92.96                             & 91.88±5.88                        & 90.02±7.34                         \\
                         & FedMeta(Meta-SGD)                                                                                                  & 68.36          & 67.89±15.11          & 60.24±21.52          & 96.39                             & 93.53±8.39                        & 89.31±14.56                         \\
                         & \textbf{\textbf{FedMeta-Per(MAML)}}                                                                                & 64.22          & 63.70±12.29          & 53.68±19.06          & 93.6                              & 93.57±5.58                        & 91.83±6.43                         \\
                         & \textbf{\textbf{FedMeta-Per(Meta-SGD)}}                                                                            & \textbf{69.97} & \textbf{69.13±14.63} & \textbf{62.42±20.94} & \textbf{96.62}                    & \textbf{95.88±3.58}               & \textbf{94.85±4.61}                 \\
    \bottomrule
    \end{tabular}
    }
\end{table}

When comparing the convergence ability of \codeword{FedMeta} and \codeword{FedMeta-Per}, because both algorithms have the participation of ML and there are similarities in the convergence of the two algorithms (Fig. \ref{fig:fedpermeta_vs_fedmeta}). It proves that ML has a certain impact on the FL system.

The ability of ML in the proposed algorithm in comparison with algorithms \codeword{FedAvg}, \codeword{FedAvgMeta}, \codeword{FedPer} and \codeword{FedPerMeta} is shown in Figure \ref{fig:fedpermeta_vs_chicken}. Accordingly, ML provides the system with fast adaptability on new clients, leading to \codeword{FedMeta-Per} convergence much faster than the old algorithms, reaching convergence thresholds from about 60\% to 85\% on CIFAR-10 and about 20\% improvement in accuracy on MNIST. More specifically, this convergence comes from performing a single fine-tune step on 20\% of the data at the client, once again demonstrating the very fast adaptability of the FL-ML system.

In addition, thanks to the construction of good personalization layers, the testing process on local clients also achieves a higher degree of convergence when comparing the proposed algorithm with \codeword{FedMeta} (Figure \ref{fig:fedpermeta_vs_fedmeta}). However, in front of a strange data distribution of new clients, these two algorithms have almost equivalent convergence ability.

\begin{figure}[h]
    \centering
    \begin{subfigure}{\textwidth}
        \centering
        \begin{subfigure}{.49\textwidth}
            \includegraphics[width=\linewidth]{img/mnist_old_metaper.eps}
            \caption{MNIST, local client}\label{mnist_old_metaper}
        \end{subfigure}
        \begin{subfigure}{.49\textwidth}
            \includegraphics[width=\linewidth]{img/mnist_new_metaper.eps}
            \caption{MNIST, new client}\label{mnist_new_metaper}
        \end{subfigure}
    \end{subfigure}
    \begin{subfigure}{\textwidth}
        \centering
        \begin{subfigure}{.49\textwidth}
            \includegraphics[width=\linewidth]{img/cifar_old_metaper.eps}
            \caption{CIFAR-10, local client}\label{cifar_old_metaper}
        \end{subfigure}
        \begin{subfigure}{.49\textwidth}
            \includegraphics[width=\linewidth]{img/cifar_new_metaper.eps}
            \caption{CIFAR-10, new client}\label{cifar_new_metaper}
        \end{subfigure}
    \end{subfigure}
    \caption{$acc_{micro}$ of FedMeta-Per and FedMeta. The end result and convergence of FedMeta-Per is significantly higher than that of FedMeta on local clients. On new clients, even though FedMeta-Per reaches a higher value, the difference in convergence is not so great.} \label{fig:fedpermeta_vs_fedmeta}
\end{figure}

\begin{figure}[h]
    \centering
    \begin{subfigure}{\textwidth}
        \centering
        \begin{subfigure}{.49\textwidth}
            \includegraphics[width=\linewidth]{img/mnist_old_per.eps}
            \caption{MNIST, local client}\label{fig:mnist_old_per}
        \end{subfigure}
        \begin{subfigure}{.49\textwidth}
            \includegraphics[width=\linewidth]{img/mnist_new_per.eps}
            \caption{MNIST, new client}\label{mnist_new_per}
        \end{subfigure}
    \end{subfigure}
    \begin{subfigure}{\textwidth}
        \centering
        \begin{subfigure}{.49\textwidth}
            \includegraphics[width=\linewidth]{img/cifar_old_per.eps}
            \caption{CIFAR-10, local client}\label{cifar_old_per}
        \end{subfigure}
        \begin{subfigure}{.49\textwidth}
            \includegraphics[width=\linewidth]{img/cifar_new_per.eps}
            \caption{CIFAR-10, new client}\label{cifar_new_per}
        \end{subfigure}
    \end{subfigure}
    \caption{$acc_{micro}$ of FedMeta-Per, FedAvg and FedPer. FedMeta-Per's convergence and accuracy are superior to those of FedAvg and FedPer algorithms.} \label{fig:fedpermeta_vs_chicken}
\end{figure}

\textbf{Personalization ability}. Observe the standard deviation of the algorithms \codeword{FedMeta}, \codeword{FedAvg} and \codeword{FedPer} in Table \ref{tab:compare}, we can see the standard deviation in the results of \codeword{FedMeta} is much smaller than the rest of the algorithms. It shows that the personalization of the FL system has been improved many times thanks to the training of ML algorithms as well as the fine-tune execution on the support set to capture the characteristics of a new data set. However, as mentioned above, this ability can completely be improved. With new suggestions during inference phase, \codeword{FedMeta-Per} further reduces the standard deviations on the scales. Specifically, after combining the fine-tune of the model on the support set of local data and maintaining the personalization layer at each client, for the local clients, the standard deviation decreases from 4\% to 14\% on CIFAR-10 and from 1\% to 5\% on MNIST while the averages are still superior. On new clients, the mean values are higher but the standard deviation in some cases is not actually smaller than the previous algorithms. This is because the personalization layers in the deep neural network of new clients have not really matched that user yet. However, over time, when new clients participate in one or a few steps of global training, they will build up good personalization layers for themselves, resulting in the metrics reaching the same value as local clients.

\section{Conclusion}

Through the research process, we combine ML algorithms and PL techniques into the FL system, to improve the accuracy as well as the ability to personalize for each user of the system on non-IID data. Experimentally, we prove the effectiveness of the proposed algorithm \codeword{FedMeta-Per} compared with algorithms \codeword{FedAvg}, \codeword{FedPer}, \codeword{FedMeta} over 50 users with two datasets CIFAR-10 and MNIST. In which, it can be explained that achieving high results is based on two inherited factors: (1) - Fast adaptability on new data set of the proposed algorithm inherited from ML algorithms, (2) - High personalization ability for each user inherited from personalization layers of PL technique and model fine-tuning on support set of ML algorithms.

In the future, bilevel optimization-based algorithms (\codeword{FO-MAML} \cite{finn2017model}, \codeword{iMAML} \cite{rajeswaran2019meta}, \codeword{Reptile}) can be integrated into the system. The search and clustering of users so that each user finds the best set of partial parameters should also be further studied to increase the performance of the system. In addition, the issue of information security between the server and the client should also be considered to make the system more practical.

% \begin{figure}[H]
%     \includegraphics[width=\textwidth]{img/cifar_new_metaper.eps}
%     \caption{A figure caption is always placed below the illustration. Please note that short captions are centered, while long ones are justified by the macro package automatically.} \label{fig1}
% \end{figure}
%
% the environments 'definition', 'lemma', 'proposition', 'corollary',
% 'remark', and 'example' are defined in the LLNCS documentclass as well.
%
%
% ---- Bibliography ----
%
% BibTeX users should specify bibliography style 'splncs04'.
% References will then be sorted and formatted in the correct style.
%
\bibliographystyle{splncs04}
\bibliography{mybibliography}

\appendix
\section{Experimental Details}
\label{appendix}

\subsection{Datasets}

The notation $C_{train} = \{c^{train}_1,...,c^{train}_{50}\}$ is the set of clients used in training, $C_{test} = \{ c^{test}_1,...,c^{test}_{50}\}$ is the set of clients used in the test, $N$ is the total number of data points, we have the number of training data points and test data points in turn is:

\begin{equation*}
    N_{train} = \sum_{i=1}^{50} \left|c^{train}_i\right| = 0.75N
\end{equation*}
\begin{equation*}
    N_{test} = \sum_{i=1}^{50} \left|c^{test}_i\right| = 0.25N
\end{equation*}

In ML implementation, notation $c^{train}_i = \{\mathcal{D}_{train(i)}^{support}, \mathcal{D}_{train(i)}^{query} \}$, $c^{test}_i = \{\mathcal{D}_{test(i)}^{support}, \mathcal{D}_{test(i)}^{query}\}$. We have the amount of data contained in the support and query sets of client $i$ respectively:

\begin{equation*}
    N_{train/test(i)}^{support} = \left|\mathcal{D}_{train/test(i)}^{support}\right| = 0.2 \left|c_i^{train/test}\right|
\end{equation*}
\begin{equation*}
    N_{train/test(i)}^{query} = \left|\mathcal{D}_{train/test(i)}^{query}\right| = 0.8 \left|c^{train/test}_i\right|
\end{equation*}

Client $c_j^{test} \in C_{test}$ is called a local client if there exists a client $c_i^{train}\in C_{train}$ such that $p\left((x, y)\in c_j^{test}\right) = p\left((x,y)\in c_i^{train}\right)$. Otherwise, $c_j^{test}$ is a new client if $p\left((x,y)\in c_j^{test}\right) \ne p\left((x,y)\in c_i^ {train}\right)$ for all $c_i^{train}\in C_{train}$.

\subsection{Model Architecture}
\label{model_architecture}

The study uses two simple models for feature extraction and data classification for the CIFAR-10 and MNIST datasets.

\textbf{CIFAR-10.} The model takes input images of size $(32\times32\times3)$. Two convolution layers (kernel of size $(5\times5)$, channel numbers of $6$ and $16$ respectively) are used for feature extraction. Following each convolution layer is a \codeword{MaxPooing} layer of size $(2\times2)$. The classifier consists of three linear layers whose outputs are $120$, $84$ and $10$ respectively. The activation functions used are \codeword{ReLU} and \codeword{Softmax}.

\textbf{MNIST.} The model receives flattened input images of size $(1\times784)$. Use two linear layers with outputs of 100 and 10 respectively. The activation functions used are \codeword{ReLU} and \codeword{Softmax}.

\subsection{Hyper-parameters Searching}

The hyper-parameters of the FL system of the study include: number of clients participating in training in a global training step ($\#clients/round$), number of local training steps ($\#epochs $), number of global training steps ($\#rounds$), amount of data in a data batch ($batch\_size$), number of personalization layers for algorithms using PL techniques ($\# per\_layers$) and the learning rate used in the optimization of deep neural networks by mini batch gradient descent.

To accommodate the limited configuration client hardware in the Horizontal FL scenario, this study limits $\#epochs=1$ and $batch\_size=32$. From the survey of FL experiments of recent studies, the number of clients participating in global training was selected as 2, 5 and 10, respectively. In which, $\#clients/round=5$ gives a higher result and consumes an acceptable computational cost.

For installed deep learning networks, it is natural to maintain a base layer and a personalization layer for the neural network of the MNIST dataset. For the deep learning network used for the set CIFAR-10, $\#per\_layers \in \{1,2,3\}$ (calculated from the last linear layer). Experimental results show that using the last linear layer as the personalization layer and the remaining deep layers as the base layers gives the best results.

Except for the learning rate of each algorithm, the above hyper-parameters are kept fixed during training. Table \ref{tab:fixed_hyper_param} summarizes these hyper-parameters values.

\begin{table}[h]
    \centering
    \caption{Fixed hyper-parameters in FL system}
    \label{tab:fixed_hyper_param}
    % \resizebox{\linewidth}{!}{%
    \begin{tabular}{l|ccccc} 
    \toprule
             & \#clients/round    & \#epochs           & \#rounds & batch\_size         & \multicolumn{1}{l}{\#per\_layers}  \\ 
    \hline
    MNIST    & \multirow{2}{*}{5} & \multirow{2}{*}{1} & 300      & \multirow{2}{*}{32} & \multirow{2}{*}{1}                \\
    CIFAR-10 &                    &                    & 600      &                     &                                   \\
    \bottomrule
    \end{tabular}
    % }
\end{table}

The learning hyper-parameters are searched in the range $(10^{-5}, 0.01)$ for each algorithm. Search results are presented in Table \ref{tab:hyper_param}. Empty cells indicate that hyper-parameters cannot be found for the model to converge.

\begin{table}[h]
    \centering
    \caption{Tuning learning rate for algorithms}
    \label{tab:hyper_param}
    % \resizebox{\linewidth}{!}{%
    \begin{tabular}{l|cc} 
    \toprule
    \begin{tabular}[c]{@{}l@{}}\\\end{tabular} & CIFAR-10           & MNIST                                             \\ 
    \hline
    FedAvg, FedAvgMeta                         & -                  & $10^{-5}$                                      \\
    FedPer, FedPerMeta                         & -                  & $10^{-5}$                                      \\
    FedMeta(MAML) ($\alpha,\beta$)             & $(0.01, 0.001)$    & $(0.001, 0.001)$                                \\
    FedMeta(Meta-SGD)($\alpha,\beta$)          & $(0.001, 0.001)$   & $(0.001, 5\times 10^{-4})$  \\
    FedMeta-Per(MAML)($\alpha,\beta$)          & $(0.001, 0.005)$   & $(0.001, 0.001)$                                \\
    FedMeta-Per(Meta-SGD)($\alpha,\beta$)      & $(0.01,0.01)$      & $(0.001, 5\times 10^{-4})$  \\
    \bottomrule
    \end{tabular}
    % }
\end{table}

% \begin{thebibliography}{8}
% \bibitem{ref_article1}
% Author, F.: Article title. Journal \textbf{2}(5), 99--110 (2016)

% \bibitem{ref_lncs1}
% Author, F., Author, S.: Title of a proceedings paper. In: Editor,
% F., Editor, S. (eds.) CONFERENCE 2016, LNCS, vol. 9999, pp. 1--13.
% Springer, Heidelberg (2016). \doi{10.10007/1234567890}

% \bibitem{ref_book1}
% Author, F., Author, S., Author, T.: Book title. 2nd edn. Publisher,
% Location (1999)

% \bibitem{ref_proc1}
% Author, A.-B.: Contribution title. In: 9th International Proceedings
% on Proceedings, pp. 1--2. Publisher, Location (2010)

% \bibitem{ref_url1}
% LNCS Homepage, \url{http://www.springer.com/lncs}. Last accessed 4
% Oct 2017
% \end{thebibliography}

\end{document}
